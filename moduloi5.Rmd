---
title:  "Inferencias de las Medias de Dos Poblaciones"
output:
  html_document:
    css: !expr here::here("styles/styles.css")
    toc: true
    toc_depth:  3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options("yaml.eval.expr" = TRUE)
```

# 2.5.Inferencias acerca de la Media de Dos Poblaciones  

Una de las preguntas más comunes en biología es si dos poblaciones (o grupos) difieren de alguna manera.  En esta sección nos interesa saber si hay diferencias entre las medias de esas problaciones.  Un requisito para esta comparación es que las muestras de las poblaciones sean __independientes__, al contrario de lo que estudiamos en la sección anterior en el tema de las __muestras pareadas__.  

Estaremos examinando un procedimiento estadístico basado en la __prueba _t___, pero para muestras independientes, y su análogo no-paramétrico, la __prueba U de Mann-Whitney__.  También volveremos a calcular los intervalos de confianza para la diferencia entre dos medias, y exploraremos el __poder de una prueba__, aplicado a la prueba _t_.  

## 2.5.1.Prueba t para Dos Muestras Independientes  
#### Objetivos  
__Utilizar la prueba _t_ para probar hipótesis sobre la diferencia entre muestras independientes__  

### El estadístico _t_ para dos muestras  

Al igual que en la sección anterior con una sola muestra, a partir de dos muestras de una población con distribución normal, podemos probar la siguiente hipótesis utilizando el estadístico _t_:  
$$H_0 : \mu_a = \mu_b$$
Si las medias de muestras de una población con distribución normal tienen una distribución _t_, entonces las diferencias entre esas medias también tendrán una distribución _t_.  Podemos modificar la ecuación del estadístico _t_:
$$t = \frac{(\bar x_a - \bar x_b) - (\mu_a - \mu_b)}{s_p}$$
La hipótesis nula formulada establece que las medias de las poblaciones son iguales, por lo tanto su diferencia es igual a 0. El estadístico $s_p$ es el error estándar agrupado para las dos muestras, y se calcula a partir de la varianza de las muestras.  El estadístico _t_ a utilizar es entonces:
$$t = \frac{\bar x_a - \bar x_b}{\sqrt{\frac{s_a^2}{n_a} + \frac{s_b^2}{n_b}}}$$
donde: 

> $\bar x_a,\ \bar x_b$: son las medias de las muestras  
> $s_a^2,\ s_b^2$: son las varianzas de las muestras  
> $n_a,\ n_b$: son los tamaños de las muestras  

Para encontrar el valor crítico de _t_, para un $\alpha$ establecido, necesitamos conocer los grados de libertad.  Para la distribución _t_ a partir de dos muestras, y si las varianzas de las poblaciones son iguales (más adelante veremos una prueba para esto), los grados de libertad están dados por:  
$$gl = n_a + n_b -2$$
Usualmente no estamos segura/os de la igualdad de las varianzas, y en ese caso los grados de libertad se calculan mediante una fórmula compleja (no es problema al trabajar con R), pero una aproximación a la misma es la siguiente:
$$gl \approx menor\ \{n_a - 1, n_b - 1\}$$

\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)  

### La Prueba _t_ para Dos Muestras  
> Comparando las medias de dos muestras para decidir si provienen de una o dos poblaciones  

Antes de aplicar el estadístico _t_ para la __prueba _t_ para dos muestras__, debemos corroborar que se cumplen los supuestos para la misma:  

1. las muestras fueron colectadas al azar   
2. las medidas de las variables son continuas (o discretas con un amplio ámbito de valores)  
3. la variable tiene una distribución aproximadamente normal (o el tamaño es grande, mayor de 30 por ejemplo)  

Cuando los supuestos se cumplen, la prueba _t_ tiene __poder__ (bajo error tipo II) y es __robusta__ (no afectada por alguna desviación de los supuestos).  Si no se cumplen los supuesto 2. y 3., o la muestra no es grande, debemos considerar una prueba no-paramétrica que estaremos revisando más adelante.  

#### __Ejemplo__  
Queremos comparar mediciones de la razón largo/ancho (RLA) de pelos radiculares, realizadas en dos especies de plantas del mismo género.  Asumimos que la variable RLA está distribuida de forma normal, y los estadísticos obtenidos de las muestras son los siguientes:  

|Estadístico|Especie A|Especie B|
|:------:|-----:|-----:|
|$n$|12|18|
|$\bar x$|1.28|4.43|
|$s^2$|0.112|7.072|

Usualmente se debe comprobar antes la normalidad de la variable, pero en este caso la asumimos por información previa.  Antes de examinar los datos, debemos formular nuestra hipótesis para no sesgar la prueba:  
$$H_0 : \mu_A = \mu_B$$  
$$H_A : \mu_A \neq \mu_B$$  
Vamos ahora a calcular el estadístico _t_:  
$$t = \frac{1.28 - 4.43}{\sqrt{\frac{0.112}{12} + \frac{7.072}{18}}} = -4.967$$  
Dado que la distribución _t_ es simétrica podemos usar el valor absoluto del estadístico calculado (4.967).  Utilizando la tabla de la distribución _t_ (o la función __qt__ en R) obtenemos el valor crítico (umbral) de _t_; pero antes debemos decidir como calcular los grados de libertad.  Dado que las varianzas parecen ser muy diferentes, utilizaremos la aproximación del menor valor de n - 1, en este caso 11.  
Según la tabla, el valor de _t_ para un $\alpha$ = 0.05, es 2.201. Estos resultados nos indican que podemos rechazar la hipótesis nula con seguridad (error tipo I << 0.05), y aceptar que las especies difieren en la razón longitud/ancho de los pelos radiculares.  

\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 2.5.2. Intervalo de Confianza para la Diferencia entre Dos Medias Poblacionales  

Utilizando el mismo enfoque de la sección anterior para calcular el intervalo de confianza de la media poblacional, podemos calcular el intervalo de confianza para la diferencia de las medias poblacionales.  La fórmula para un 95% de confianza es:  
$$(\bar x_a - \bar x_b) \pm t_{0.05,k}*\sqrt{\frac{s_a^2}{n_a} + \frac{s_b^2}{n_b}}$$

Para el caso del ejemplo anterior:
$$IC\ 95 \%\ \mu_B - \mu_A = (4.43 - 1.28) \pm 2.201 \sqrt{\frac{7.072}{18} + \frac{0.112}{12}}$$  
$$= 3.15 \pm 1.40 = 1.75,\ 4.55$$  
Este resultado nos indica que estamos 95% segura/os de que la diferencia entre las medias de la razón longitud/ancho de pelos radiculares de las especies A y B, es al menos 1.75 y no sobrepasa 4.55  


\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

### Prueba _t_ Mediante R  
La plataforma RStudio provee funciones de R para realizar la prueba _t_, intervalo de confianza, y las visualizaciones y cálculos de estadísticas básicas de dos variables.  

#### __Ejercicio__  
Queremos comparar las medias de la masa de dos muestras de semillas de la especie _Thespesia populnea_ (emajagüilla), tomadas en dos años.


\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html) 

## 2.5.3.Supuestos y Pruebas No-paramétricas
#### Objetivos  
__Realizar pruebas de independencia de dos muestras mediante un método no-paramétrico__  

Cuando los datos no cumplen con los supuestos para la prueba _t_, y además las muestras son pequeñas, podemos usar una prueba no-paramétrica (que no depende de los parámetros de la distribución normal) llamada __prueba U de Mann-Whitney__.  Con esta prueba queremos saber si las muestras poseen medianas ($\theta$) idénticas:  
$$H_0 : \theta_1 = \theta_2$$  
Aunque esta prueba es independiente de los supuestos anteriores de la pruenba _t_, posee sus propios supuestos:  

1. las muestras se toman al azar e independientes una de otra.  
2. la variable medida es ordinal, discreta o continua.  
3. las muestras tienen una distribución de forma y dispersión similar.  

### Preparación de los Datos para la Prueba  
> Codificar su rango de menor a mayor  

Para facilitar el proceso de preparación para los cálculos, los datos de cada muestra se ordenan de menor a mayor.  Los datos se codifican de menor a mayor, en una misma secuencia con las dos muestras, empezando en 1.  Cuando hay valores iguales, se suman las posiciones (código) que tendrían si fueran diferentes y se dividen entre el número de valores iguales.  

La siguiente tabla ilustra el proceso.  Los gatos machos pueden ser muy territoriales en ciertas localidades.  En un estudio se determinó el área territorial (hectáreas) de gatos machos, en dos localidades (A y B): 
```{r umanncat, echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)
library(dplyr)
# vector localidad A
la <- c(7,7,10,14,17,20.6,21,21,24,"NA")
# rango localidad A
ra <- c(1.5,1.5,4.5,6,7,9,11,11,13,"NA")
# vector localidad B
lb <- c(8,10,18,21,29,32,35,36,37,"45")
# rango localidad B
rb <- c(3,"4.5",8,11,14,15,16,17,18,19)
# dataframe
gatos <- data.frame(la,ra,lb,rb)
# nombres columnas
names(gatos) <- c("Territorio LA, ha", "Rango LA", "Territotrio LB, ha", "Rango LB")
gatos %>%
  kbl(caption = "Tabla 1. Tamaño de territorio (ha) de gatos machos, en dos localidades (LA, LB), y codificación en rango de menor a mayor") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

Las hipótesis que deseamos probar:  
$$H_0 : \theta_A = \theta_B$$  
_versus_:
$$H_0 : \theta_A \neq \theta_B$$ 
A partir de los datos anteriores se pueden calcular los estadísticos que necesitamos para la prueba: mediana, sumatoria de rangos de cada muestra ($\sum R_A$ y $\sum R_B$), y el tamaño de las muestras, _n_.  

|Estadístico|Localidad A|Localidad B|
|:---|---:|---:|
|Mediana|17|30.5|
|_n_|9|10|
|$\sum R$|64.5|125.5|  

El estadístico U se calcula para ambas muestras:  
$$U_A = n_A n_B + \frac{n_A(n_A + 1)}{2} - \sum R_A$$
$$U_B = n_A n_B - U_A$$
y obtenemos $U_A$ = 70.5 y $U_B$ = 19.5.  Se utiliza el valor mayor para comparar con el valor crítico de _U_ en la [Tabla U-Mann-Whitney](https://drive.google.com/file/d/1424rM80eN5CUszoIY24ARLQaNHKHI9Qg/view?usp=sharing), para $\alpha$ = 0.05 (dos colas), $n_1$ = 9 y $n_2$ = 10.  Al ser el valor $U_A$ mayor que el valor de $U_{0.05,9,10}$ = 70, podemos rechazar la hipótesis nula de igualdad de medianas, y concluir que los territorios de gatos machos son mayores en la localidad B.  

### Prueba U de Mann-Whitney con R  
La prueba U de Mann-Whitney se realiza en R usando la misma función de la prueba Wilcoxon, pero sin especificar para prueba pareada.  Solamente se proveen los datos crudos, sin tener que realizar el ordenamiento ni la codificación.  
```{r message=FALSE, warning=FALSE}
# datos localidades
la <- c(7,7,10,14,17,20.6,21,21,24)
lb <- c(8,10,18,21,29,32,35,36,37,45)
# prueba
wilcox.test(lb, la, alternative = "two.sided")
```

\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

## 2.5.4.Poder de la Prueba

Referirse al capítulo 10, sección 10.4 del libro de Havel _et al._, 2019. 

\

[  __Home__](https://dsfernandez.github.io/bioestadisticas/index.html)

